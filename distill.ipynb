{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_kan import KAN\n",
    "\n",
    "# Train on MNIST\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "valset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KAN(\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x KANLinear(\n",
       "      (base_activation): SiLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model = KAN([28 * 28, 64, 10])\n",
    "teacher_model.load_state_dict(torch.load('teacher.pth'))\n",
    "teacher_model.to(device)\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KAN(\n",
       "  (layers): ModuleList(\n",
       "    (0): KANLinear(\n",
       "      (base_activation): SiLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = KAN([28 * 28, 10])  # Smaller intermediate layer\n",
    "student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss(y_student, y_teacher, y_true, T, alpha):\n",
    "    soft_loss = nn.KLDivLoss()(F.log_softmax(y_student/T, dim=1),\n",
    "                                F.softmax(y_teacher/T, dim=1))\n",
    "    hard_loss = nn.CrossEntropyLoss()(y_student, y_true)\n",
    "    return alpha * soft_loss * T * T + (1 - alpha) * hard_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(student_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "temperature = 1.5\n",
    "alpha = 0.5\n",
    "max_val_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|██████████| 938/938 [00:16<00:00, 56.46it/s, loss=0.133] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val Loss: 0.16550178825855255, Val Accuracy: 0.9187898089171974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 56.57it/s, loss=0.0927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Val Loss: 0.14655467867851257, Val Accuracy: 0.9290406050955414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 56.54it/s, loss=0.0621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Val Loss: 0.13744647800922394, Val Accuracy: 0.9322253184713376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 56.93it/s, loss=0.0623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Val Loss: 0.1336313784122467, Val Accuracy: 0.9324243630573248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 56.98it/s, loss=0.259] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Val Loss: 0.13036027550697327, Val Accuracy: 0.9344148089171974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 57.08it/s, loss=0.0737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Val Loss: 0.1313268542289734, Val Accuracy: 0.9342157643312102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 56.30it/s, loss=0.145] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Val Loss: 0.12771864235401154, Val Accuracy: 0.9345143312101911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 58.17it/s, loss=0.185] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Val Loss: 0.1260286271572113, Val Accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 58.22it/s, loss=0.104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Val Loss: 0.1250699907541275, Val Accuracy: 0.9358081210191083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 58.27it/s, loss=0.139] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Val Loss: 0.12472017854452133, Val Accuracy: 0.9366042993630573\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    student_model.train()\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for i, (images, labels) in enumerate(pbar):\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get teacher and student outputs\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images)\n",
    "            student_outputs = student_model(images)\n",
    "\n",
    "            # Calculate combined loss\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Update the learning rate\n",
    "    student_model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            student_outputs = student_model(images)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images)\n",
    "            val_loss += distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            val_accuracy += (\n",
    "                (student_outputs.argmax(dim=1) == labels.to(device)).float().mean().item()\n",
    "            )\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    if val_accuracy > max_val_acc:\n",
    "        torch.save(student_model.state_dict(), 'student_model.pth')\n",
    "        max_val_acc = val_accuracy\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\"\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, valloader):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            test_loss += nn.CrossEntropyLoss()(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the NOT distilled student model on the test set: 93.65%\n",
      "Accuracy of the DISTILLED student model on the test set: 93.75%\n",
      "Accuracy of the teacher model on the test set: 97.23%\n"
     ]
    }
   ],
   "source": [
    "# Load and evaluate the model\n",
    "\n",
    "student_model.load_state_dict(torch.load('student_not_distilled.pth'))\n",
    "acc = testing(student_model, valloader)\n",
    "print(f'Accuracy of the NOT distilled student model on the test set: {acc}%')\n",
    "\n",
    "student_model.load_state_dict(torch.load('student_model.pth'))\n",
    "acc = testing(student_model, valloader)\n",
    "print(f'Accuracy of the DISTILLED student model on the test set: {acc}%')\n",
    "\n",
    "teacher_model.load_state_dict(torch.load('teacher.pth'))\n",
    "acc = testing(teacher_model, valloader)\n",
    "print(f'Accuracy of the teacher model on the test set: {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
